{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to Python 3.13.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc1051d",
   "metadata": {},
   "source": [
    "# MATTEO OLIVER BEKINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eabc0b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel,ConstantKernel, ExpSineSquared, DotProduct, Matern, RationalQuadratic\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from data_viz import read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed062ad8",
   "metadata": {},
   "source": [
    "I will try to fit a variety of classification methods to find the best one:\n",
    "* Random Forest\n",
    "* Gaussian Classifier\n",
    "* Gaussian Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d4c782",
   "metadata": {},
   "source": [
    "#### DATA PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1b179eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: C:\\Users\\matte\\OneDrive\\Documents\\UC3M\\UC3M_Notes\\Machine_Learning II\\Kaggle_Competition\\data\\train_set.csv\n",
      "Data directory: C:\\Users\\matte\\OneDrive\\Documents\\UC3M\\UC3M_Notes\\Machine_Learning II\\Kaggle_Competition\\data\\test_set.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_17</th>\n",
       "      <th>feat_18</th>\n",
       "      <th>feat_19</th>\n",
       "      <th>feat_20</th>\n",
       "      <th>feat_21</th>\n",
       "      <th>feat_22</th>\n",
       "      <th>feat_23</th>\n",
       "      <th>feat_24</th>\n",
       "      <th>feat_25</th>\n",
       "      <th>feat_26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>0.2616</td>\n",
       "      <td>2.5025</td>\n",
       "      <td>-11.1660</td>\n",
       "      <td>-0.3815</td>\n",
       "      <td>0.2319</td>\n",
       "      <td>-1.4798</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>-4.1052</td>\n",
       "      <td>0.5083</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.9826</td>\n",
       "      <td>-12.1896</td>\n",
       "      <td>1.3346</td>\n",
       "      <td>-0.1038</td>\n",
       "      <td>-0.1328</td>\n",
       "      <td>-0.2646</td>\n",
       "      <td>11.5052</td>\n",
       "      <td>0.1535</td>\n",
       "      <td>0.0963</td>\n",
       "      <td>0.3345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0.3874</td>\n",
       "      <td>1.0461</td>\n",
       "      <td>-9.4303</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>-0.9858</td>\n",
       "      <td>-0.4959</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>-0.3943</td>\n",
       "      <td>1.0242</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.9471</td>\n",
       "      <td>-8.3548</td>\n",
       "      <td>6.0248</td>\n",
       "      <td>0.0607</td>\n",
       "      <td>-0.1689</td>\n",
       "      <td>-0.1911</td>\n",
       "      <td>9.4314</td>\n",
       "      <td>0.1386</td>\n",
       "      <td>3.7278</td>\n",
       "      <td>-0.5929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>5.5317</td>\n",
       "      <td>-10.4569</td>\n",
       "      <td>0.1915</td>\n",
       "      <td>-0.8280</td>\n",
       "      <td>-0.2836</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>-3.8544</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2284</td>\n",
       "      <td>-0.8834</td>\n",
       "      <td>2.4716</td>\n",
       "      <td>0.2844</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>-0.4979</td>\n",
       "      <td>10.3966</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>-1.1622</td>\n",
       "      <td>-0.2638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0.3544</td>\n",
       "      <td>-0.2149</td>\n",
       "      <td>-3.9802</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>0.5326</td>\n",
       "      <td>-0.4676</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>3.0157</td>\n",
       "      <td>-1.4849</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9018</td>\n",
       "      <td>0.2686</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.2039</td>\n",
       "      <td>-2.2213</td>\n",
       "      <td>3.6265</td>\n",
       "      <td>-0.1575</td>\n",
       "      <td>1.5227</td>\n",
       "      <td>4.7911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0.3118</td>\n",
       "      <td>3.2238</td>\n",
       "      <td>-5.9532</td>\n",
       "      <td>-0.0805</td>\n",
       "      <td>1.1114</td>\n",
       "      <td>1.3232</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>3.4671</td>\n",
       "      <td>-0.7132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7276</td>\n",
       "      <td>-2.2058</td>\n",
       "      <td>-3.4741</td>\n",
       "      <td>0.2296</td>\n",
       "      <td>-0.1185</td>\n",
       "      <td>1.3222</td>\n",
       "      <td>6.1321</td>\n",
       "      <td>0.3408</td>\n",
       "      <td>1.8497</td>\n",
       "      <td>-0.9679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    target  feat_0  feat_1   feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  \\\n",
       "ID                                                                            \n",
       "0     True  0.2616  2.5025 -11.1660 -0.3815  0.2319 -1.4798  0.0072 -4.1052   \n",
       "1     True  0.3874  1.0461  -9.4303  0.0100 -0.9858 -0.4959  0.0044 -0.3943   \n",
       "2     True  0.2276  5.5317 -10.4569  0.1915 -0.8280 -0.2836  0.0052 -3.8544   \n",
       "3    False  0.3544 -0.2149  -3.9802  0.1635  0.5326 -0.4676  0.0268  3.0157   \n",
       "4    False  0.3118  3.2238  -5.9532 -0.0805  1.1114  1.3232  0.0190  3.4671   \n",
       "\n",
       "    feat_8  ...  feat_17  feat_18  feat_19  feat_20  feat_21  feat_22  \\\n",
       "ID          ...                                                         \n",
       "0   0.5083  ...  -4.9826 -12.1896   1.3346  -0.1038  -0.1328  -0.2646   \n",
       "1   1.0242  ...  -1.9471  -8.3548   6.0248   0.0607  -0.1689  -0.1911   \n",
       "2   0.9625  ...   1.2284  -0.8834   2.4716   0.2844   0.0231  -0.4979   \n",
       "3  -1.4849  ...      NaN   0.9018   0.2686   0.0460   0.2039  -2.2213   \n",
       "4  -0.7132  ...  -0.7276  -2.2058  -3.4741   0.2296  -0.1185   1.3222   \n",
       "\n",
       "    feat_23  feat_24  feat_25  feat_26  \n",
       "ID                                      \n",
       "0   11.5052   0.1535   0.0963   0.3345  \n",
       "1    9.4314   0.1386   3.7278  -0.5929  \n",
       "2   10.3966   0.1455  -1.1622  -0.2638  \n",
       "3    3.6265  -0.1575   1.5227   4.7911  \n",
       "4    6.1321   0.3408   1.8497  -0.9679  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = read_data('train_set.csv')\n",
    "test_data = read_data('test_set.csv')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af48bbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['target', 'feat_0', 'feat_1', 'feat_2', 'feat_3', 'feat_4', 'feat_5',\n",
      "       'feat_6', 'feat_7', 'feat_8', 'feat_9', 'feat_10', 'feat_11', 'feat_12',\n",
      "       'feat_13', 'feat_14', 'feat_15', 'feat_16', 'feat_17', 'feat_18',\n",
      "       'feat_19', 'feat_20', 'feat_21', 'feat_22', 'feat_23', 'feat_24',\n",
      "       'feat_25', 'feat_26'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9edf4bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any missing values in train data: True\n",
      "Any missing values in test data: False\n"
     ]
    }
   ],
   "source": [
    "print(\"Any missing values in train data:\", train_data.isnull().any().any())\n",
    "print(\"Any missing values in test data:\", test_data.isnull().any().any())\n",
    "\n",
    "clean_train_data = train_data.dropna()\n",
    "clean_test_data = test_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7042ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classification_problem(train_data, test_data):\n",
    "    X_train = train_data.drop(columns='target')\n",
    "    y_train = train_data['target']\n",
    "\n",
    "    # Test data doesn't have 'target' column (it's what we need to predict)\n",
    "    X_test = test_data\n",
    "    \n",
    "    return X_train, y_train, X_test\n",
    "\n",
    "X_train, y_train, X_test = binary_classification_problem(clean_train_data, clean_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec720860",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ea848ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_classification(X_train, y_train):\n",
    "    mod = RandomForestClassifier(n_estimators=100, max_leaf_nodes=50, random_state=42)\n",
    "    mod.fit(X_train, y_train)\n",
    "\n",
    "    # Create relevance array\n",
    "    feature_relevance_rf = np.zeros(X_train.shape[1])\n",
    "    for tree in mod.estimators_:\n",
    "        feature_relevance_rf += tree.feature_importances_\n",
    "    feature_relevance_rf /= mod.n_estimators\n",
    "\n",
    "    sorted_indices_rf_79 = np.argsort(feature_relevance_rf)[::-1]\n",
    "    print(\"Feature ranking (Random Forest):\")\n",
    "    for rank, index in enumerate(sorted_indices_rf_79):\n",
    "        print(f\"{rank + 1}. Feature {index} (Relevance: {feature_relevance_rf[index]:.4f})\")\n",
    "\n",
    "    print(f\"Sum of feature relevances: {np.sum(feature_relevance_rf):.4f}\")\n",
    "    return mod, feature_relevance_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1b8a30",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c17f845d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking (Random Forest):\n",
      "1. Feature 9 (Relevance: 0.1551)\n",
      "2. Feature 6 (Relevance: 0.1268)\n",
      "3. Feature 11 (Relevance: 0.0874)\n",
      "4. Feature 13 (Relevance: 0.0788)\n",
      "5. Feature 5 (Relevance: 0.0742)\n",
      "6. Feature 19 (Relevance: 0.0683)\n",
      "7. Feature 16 (Relevance: 0.0536)\n",
      "8. Feature 15 (Relevance: 0.0481)\n",
      "9. Feature 8 (Relevance: 0.0268)\n",
      "10. Feature 4 (Relevance: 0.0262)\n",
      "11. Feature 10 (Relevance: 0.0257)\n",
      "12. Feature 23 (Relevance: 0.0230)\n",
      "13. Feature 18 (Relevance: 0.0226)\n",
      "14. Feature 0 (Relevance: 0.0193)\n",
      "15. Feature 14 (Relevance: 0.0170)\n",
      "16. Feature 2 (Relevance: 0.0164)\n",
      "17. Feature 24 (Relevance: 0.0145)\n",
      "18. Feature 25 (Relevance: 0.0136)\n",
      "19. Feature 3 (Relevance: 0.0132)\n",
      "20. Feature 26 (Relevance: 0.0127)\n",
      "21. Feature 22 (Relevance: 0.0120)\n",
      "22. Feature 21 (Relevance: 0.0115)\n",
      "23. Feature 7 (Relevance: 0.0115)\n",
      "24. Feature 20 (Relevance: 0.0114)\n",
      "25. Feature 1 (Relevance: 0.0104)\n",
      "26. Feature 17 (Relevance: 0.0101)\n",
      "27. Feature 12 (Relevance: 0.0097)\n",
      "Sum of feature relevances: 1.0000\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('../outputs'):\n",
    "    os.makedirs('../outputs')\n",
    "mod, feature_relevance_rf = random_forest_classification(X_train, y_train)\n",
    "predictions = mod.predict(X_test)\n",
    "output_df = pd.DataFrame({'ID': test_data.index, 'target': predictions})\n",
    "output_df.to_csv('../outputs/rf_predictions_with_na.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c33b92",
   "metadata": {},
   "source": [
    "### GAUSSIAN CLASSIFIER - ARD - NOISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47beb47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_process_classification(X_train, y_train,length_scale_init=2.0):\n",
    "    kernel = ConstantKernel(1.0) * RBF(length_scale=[length_scale_init] * 27, length_scale_bounds=[(1e-3, 1e10)] * 27) + WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e5))\n",
    "\n",
    "    print('Preparing Gaussian Process Classifier...')\n",
    "    mod = GaussianProcessClassifier(kernel=kernel, random_state=42, n_restarts_optimizer=2)\n",
    "    print('Fitting Gaussian Process Classifier...')\n",
    "    mod.fit(X_train, y_train)\n",
    "    print('Gaussian Process Classifier fitted.')\n",
    "\n",
    "    # Debug: Print all kernel parameters\n",
    "    print(\"\\nKernel parameters:\")\n",
    "    print(mod.kernel_.get_params())\n",
    "\n",
    "    # Extract lengthscales - adjust key based on kernel structure\n",
    "    kernel_params = mod.kernel_.get_params()\n",
    "    # The structure is: k1__k2__length_scale (ConstantKernel * RBF) + WhiteKernel\n",
    "    lengthscales_gp = kernel_params.get('k1__k2__length_scale', None)\n",
    "\n",
    "    if lengthscales_gp is None:\n",
    "        print(\"Trying alternative key...\")\n",
    "        lengthscales_gp = kernel_params.get('k2__length_scale', None)\n",
    "\n",
    "    if lengthscales_gp is None:\n",
    "        print(\"ERROR: Could not find lengthscales. Available keys:\")\n",
    "        for key in kernel_params.keys():\n",
    "            print(f\"  - {key}\")\n",
    "    else:\n",
    "        # Sort in descending order of relevance (ascending order of lengthscales)\n",
    "        sorted_indices_gp = np.argsort(lengthscales_gp)\n",
    "\n",
    "        # Print the feature ranking\n",
    "        print(\"Feature ranking (most to least relevant):\")\n",
    "        for rank, index in enumerate(sorted_indices_gp[:10]):  # Show top 10 most relevant features\n",
    "            print(f\"{rank + 1}. Feature {index} (Lengthscale: {lengthscales_gp[index]:.4f})\")\n",
    "    return mod, lengthscales_gp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706e7aac",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dcdfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('../outputs'):\n",
    "    os.makedirs('../outputs')\n",
    "mod, lengthscales_gp = gaussian_process_classification(X_train, y_train)\n",
    "predictions = mod.predict(X_test)\n",
    "output_df = pd.DataFrame({'ID': test_data.index, 'target': predictions})\n",
    "output_df.to_csv('../outputs/gp_predictions_with_na.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c2705",
   "metadata": {},
   "source": [
    "## FULL IMPUTED DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a4417a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: C:\\Users\\matte\\OneDrive\\Documents\\UC3M\\UC3M_Notes\\Machine_Learning II\\Kaggle_Competition\\data\\full_train_set_imputed.csv\n",
      "Data directory: C:\\Users\\matte\\OneDrive\\Documents\\UC3M\\UC3M_Notes\\Machine_Learning II\\Kaggle_Competition\\data\\test_set.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_17</th>\n",
       "      <th>feat_18</th>\n",
       "      <th>feat_19</th>\n",
       "      <th>feat_20</th>\n",
       "      <th>feat_21</th>\n",
       "      <th>feat_22</th>\n",
       "      <th>feat_23</th>\n",
       "      <th>feat_24</th>\n",
       "      <th>feat_25</th>\n",
       "      <th>feat_26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>0.2616</td>\n",
       "      <td>2.5025</td>\n",
       "      <td>-11.1660</td>\n",
       "      <td>-0.3815</td>\n",
       "      <td>0.2319</td>\n",
       "      <td>-1.4798</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>-4.1052</td>\n",
       "      <td>0.5083</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.982600</td>\n",
       "      <td>-12.1896</td>\n",
       "      <td>1.3346</td>\n",
       "      <td>-0.1038</td>\n",
       "      <td>-0.1328</td>\n",
       "      <td>-0.2646</td>\n",
       "      <td>11.5052</td>\n",
       "      <td>0.1535</td>\n",
       "      <td>0.0963</td>\n",
       "      <td>0.3345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0.3874</td>\n",
       "      <td>1.0461</td>\n",
       "      <td>-9.4303</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>-0.9858</td>\n",
       "      <td>-0.4959</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>-0.3943</td>\n",
       "      <td>1.0242</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.947100</td>\n",
       "      <td>-8.3548</td>\n",
       "      <td>6.0248</td>\n",
       "      <td>0.0607</td>\n",
       "      <td>-0.1689</td>\n",
       "      <td>-0.1911</td>\n",
       "      <td>9.4314</td>\n",
       "      <td>0.1386</td>\n",
       "      <td>3.7278</td>\n",
       "      <td>-0.5929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>5.5317</td>\n",
       "      <td>-10.4569</td>\n",
       "      <td>0.1915</td>\n",
       "      <td>-0.8280</td>\n",
       "      <td>-0.2836</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>-3.8544</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>...</td>\n",
       "      <td>1.228400</td>\n",
       "      <td>-0.8834</td>\n",
       "      <td>2.4716</td>\n",
       "      <td>0.2844</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>-0.4979</td>\n",
       "      <td>10.3966</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>-1.1622</td>\n",
       "      <td>-0.2638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0.3544</td>\n",
       "      <td>-0.2149</td>\n",
       "      <td>-3.9802</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>0.5326</td>\n",
       "      <td>-0.4676</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>3.0157</td>\n",
       "      <td>-1.4849</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.652831</td>\n",
       "      <td>0.9018</td>\n",
       "      <td>0.2686</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.2039</td>\n",
       "      <td>-2.2213</td>\n",
       "      <td>3.6265</td>\n",
       "      <td>-0.1575</td>\n",
       "      <td>1.5227</td>\n",
       "      <td>4.7911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0.3118</td>\n",
       "      <td>3.2238</td>\n",
       "      <td>-5.9532</td>\n",
       "      <td>-0.0805</td>\n",
       "      <td>1.1114</td>\n",
       "      <td>1.3232</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>3.4671</td>\n",
       "      <td>-0.7132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.727600</td>\n",
       "      <td>-2.2058</td>\n",
       "      <td>-3.4741</td>\n",
       "      <td>0.2296</td>\n",
       "      <td>-0.1185</td>\n",
       "      <td>1.3222</td>\n",
       "      <td>6.1321</td>\n",
       "      <td>0.3408</td>\n",
       "      <td>1.8497</td>\n",
       "      <td>-0.9679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    target  feat_0  feat_1   feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  \\\n",
       "ID                                                                            \n",
       "0     True  0.2616  2.5025 -11.1660 -0.3815  0.2319 -1.4798  0.0072 -4.1052   \n",
       "1     True  0.3874  1.0461  -9.4303  0.0100 -0.9858 -0.4959  0.0044 -0.3943   \n",
       "2     True  0.2276  5.5317 -10.4569  0.1915 -0.8280 -0.2836  0.0052 -3.8544   \n",
       "3    False  0.3544 -0.2149  -3.9802  0.1635  0.5326 -0.4676  0.0268  3.0157   \n",
       "4    False  0.3118  3.2238  -5.9532 -0.0805  1.1114  1.3232  0.0190  3.4671   \n",
       "\n",
       "    feat_8  ...   feat_17  feat_18  feat_19  feat_20  feat_21  feat_22  \\\n",
       "ID          ...                                                          \n",
       "0   0.5083  ... -4.982600 -12.1896   1.3346  -0.1038  -0.1328  -0.2646   \n",
       "1   1.0242  ... -1.947100  -8.3548   6.0248   0.0607  -0.1689  -0.1911   \n",
       "2   0.9625  ...  1.228400  -0.8834   2.4716   0.2844   0.0231  -0.4979   \n",
       "3  -1.4849  ... -0.652831   0.9018   0.2686   0.0460   0.2039  -2.2213   \n",
       "4  -0.7132  ... -0.727600  -2.2058  -3.4741   0.2296  -0.1185   1.3222   \n",
       "\n",
       "    feat_23  feat_24  feat_25  feat_26  \n",
       "ID                                      \n",
       "0   11.5052   0.1535   0.0963   0.3345  \n",
       "1    9.4314   0.1386   3.7278  -0.5929  \n",
       "2   10.3966   0.1455  -1.1622  -0.2638  \n",
       "3    3.6265  -0.1575   1.5227   4.7911  \n",
       "4    6.1321   0.3408   1.8497  -0.9679  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = read_data('full_train_set_imputed.csv')\n",
    "test_data = read_data('test_set.csv')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9f9d1b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any missing values in train data: False\n",
      "Any missing values in test data: False\n"
     ]
    }
   ],
   "source": [
    "print(\"Any missing values in train data:\", train_data.isnull().any().any())\n",
    "print(\"Any missing values in test data:\", test_data.isnull().any().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b4293b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test = binary_classification_problem(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa6f50e",
   "metadata": {},
   "source": [
    "## RANDOM FOREST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9594c58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking (Random Forest):\n",
      "1. Feature 9 (Relevance: 0.1635)\n",
      "2. Feature 6 (Relevance: 0.1286)\n",
      "3. Feature 11 (Relevance: 0.1033)\n",
      "4. Feature 5 (Relevance: 0.0795)\n",
      "5. Feature 13 (Relevance: 0.0784)\n",
      "6. Feature 19 (Relevance: 0.0692)\n",
      "7. Feature 16 (Relevance: 0.0562)\n",
      "8. Feature 15 (Relevance: 0.0387)\n",
      "9. Feature 4 (Relevance: 0.0321)\n",
      "10. Feature 18 (Relevance: 0.0262)\n",
      "11. Feature 8 (Relevance: 0.0257)\n",
      "12. Feature 10 (Relevance: 0.0250)\n",
      "13. Feature 23 (Relevance: 0.0206)\n",
      "14. Feature 2 (Relevance: 0.0181)\n",
      "15. Feature 0 (Relevance: 0.0141)\n",
      "16. Feature 14 (Relevance: 0.0130)\n",
      "17. Feature 26 (Relevance: 0.0125)\n",
      "18. Feature 24 (Relevance: 0.0110)\n",
      "19. Feature 25 (Relevance: 0.0104)\n",
      "20. Feature 3 (Relevance: 0.0102)\n",
      "21. Feature 22 (Relevance: 0.0101)\n",
      "22. Feature 7 (Relevance: 0.0101)\n",
      "23. Feature 21 (Relevance: 0.0097)\n",
      "24. Feature 12 (Relevance: 0.0091)\n",
      "25. Feature 20 (Relevance: 0.0090)\n",
      "26. Feature 17 (Relevance: 0.0081)\n",
      "27. Feature 1 (Relevance: 0.0076)\n",
      "Sum of feature relevances: 1.0000\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir('../outputs'):\n",
    "    os.makedirs('../outputs')\n",
    "mod, feature_relevance_rf = random_forest_classification(X_train, y_train)\n",
    "predictions = mod.predict(X_test)\n",
    "output_df = pd.DataFrame({'ID': test_data.index, 'target': predictions})\n",
    "output_df.to_csv('../outputs/rf_predictions_without_na.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbc6e83",
   "metadata": {},
   "source": [
    "## GAUSSIAN CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a476f129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Gaussian Process Classifier...\n",
      "Fitting Gaussian Process Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matte\\.conda\\envs\\Optimization_Analytics\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Process Classifier fitted.\n",
      "\n",
      "Kernel parameters:\n",
      "{'k1': 3.91**2 * RBF(length_scale=[2.11, 2.85e+04, 1.44e+07, 3.72, 6.89, 6.09, 0.0244, 9.37e+04, 7.68, 1.17, 4.43, 0.0388, 1.07e+04, 0.912, 217, 6.91, 2.04, 1.08e+04, 32.6, 10.9, 614, 864, 5.38e+04, 18.6, 4.54, 4.85e+04, 6.14e+04]), 'k2': WhiteKernel(noise_level=1e-05), 'k1__k1': 3.91**2, 'k1__k2': RBF(length_scale=[2.11, 2.85e+04, 1.44e+07, 3.72, 6.89, 6.09, 0.0244, 9.37e+04, 7.68, 1.17, 4.43, 0.0388, 1.07e+04, 0.912, 217, 6.91, 2.04, 1.08e+04, 32.6, 10.9, 614, 864, 5.38e+04, 18.6, 4.54, 4.85e+04, 6.14e+04]), 'k1__k1__constant_value': np.float64(15.263042146961178), 'k1__k1__constant_value_bounds': (1e-05, 100000.0), 'k1__k2__length_scale': array([2.11208124e+00, 2.84544260e+04, 1.44312322e+07, 3.72174727e+00,\n",
      "       6.88548058e+00, 6.08598276e+00, 2.43841489e-02, 9.36954364e+04,\n",
      "       7.67670793e+00, 1.16591643e+00, 4.43189034e+00, 3.88156692e-02,\n",
      "       1.06922517e+04, 9.12130746e-01, 2.16770599e+02, 6.91247675e+00,\n",
      "       2.03814373e+00, 1.08297096e+04, 3.26009646e+01, 1.09112306e+01,\n",
      "       6.14279616e+02, 8.64201942e+02, 5.37741989e+04, 1.86345476e+01,\n",
      "       4.53680020e+00, 4.85363185e+04, 6.14154156e+04]), 'k1__k2__length_scale_bounds': [(0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0)], 'k2__noise_level': np.float64(9.999999999999997e-06), 'k2__noise_level_bounds': (1e-05, 100000.0)}\n",
      "Feature ranking (most to least relevant):\n",
      "1. Feature 6 (Lengthscale: 0.0244)\n",
      "2. Feature 11 (Lengthscale: 0.0388)\n",
      "3. Feature 13 (Lengthscale: 0.9121)\n",
      "4. Feature 9 (Lengthscale: 1.1659)\n",
      "5. Feature 16 (Lengthscale: 2.0381)\n",
      "6. Feature 0 (Lengthscale: 2.1121)\n",
      "7. Feature 3 (Lengthscale: 3.7217)\n",
      "8. Feature 10 (Lengthscale: 4.4319)\n",
      "9. Feature 24 (Lengthscale: 4.5368)\n",
      "10. Feature 5 (Lengthscale: 6.0860)\n"
     ]
    }
   ],
   "source": [
    "mod, lengthscales_gp = gaussian_process_classification(X_train, y_train)\n",
    "if not os.path.isdir('../outputs'):\n",
    "    os.makedirs('../outputs')\n",
    "predictions = mod.predict(X_test)\n",
    "output_df = pd.DataFrame({'ID': test_data.index, 'target': predictions})\n",
    "output_df.to_csv('../outputs/gp_predictions_without_na_v2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573fa3c5",
   "metadata": {},
   "source": [
    "## GAUSSIAN CLASSFIER WITH SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8fe24168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Gaussian Process Classifier...\n",
      "Fitting Gaussian Process Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matte\\.conda\\envs\\Optimization_Analytics\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:450: ConvergenceWarning: The optimal value found for dimension 2 of parameter k1__k2__length_scale is close to the specified upper bound 10000000000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\matte\\.conda\\envs\\Optimization_Analytics\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Process Classifier fitted.\n",
      "\n",
      "Kernel parameters:\n",
      "{'k1': 3.91**2 * RBF(length_scale=[15.1, 4.55e+03, 1e+10, 14.5, 7.84, 6.05, 2.94, 5.13e+03, 9.76, 3.97, 3.01, 3.87, 4.41e+03, 4.82, 3.17e+03, 5.01, 3.14, 5.07e+03, 3.17, 2.68, 1.48e+03, 5.32e+03, 5.01e+03, 5.17, 25.2, 897, 4.3e+03]), 'k2': WhiteKernel(noise_level=1e-05), 'k1__k1': 3.91**2, 'k1__k2': RBF(length_scale=[15.1, 4.55e+03, 1e+10, 14.5, 7.84, 6.05, 2.94, 5.13e+03, 9.76, 3.97, 3.01, 3.87, 4.41e+03, 4.82, 3.17e+03, 5.01, 3.14, 5.07e+03, 3.17, 2.68, 1.48e+03, 5.32e+03, 5.01e+03, 5.17, 25.2, 897, 4.3e+03]), 'k1__k1__constant_value': np.float64(15.260027129157654), 'k1__k1__constant_value_bounds': (1e-05, 100000.0), 'k1__k2__length_scale': array([1.51070230e+01, 4.54682656e+03, 1.00000000e+10, 1.45234488e+01,\n",
      "       7.83945116e+00, 6.04906342e+00, 2.94287331e+00, 5.12779041e+03,\n",
      "       9.76413621e+00, 3.96803052e+00, 3.00748248e+00, 3.86897500e+00,\n",
      "       4.40996260e+03, 4.81962795e+00, 3.16876623e+03, 5.01127248e+00,\n",
      "       3.14288626e+00, 5.06627890e+03, 3.17132642e+00, 2.68302937e+00,\n",
      "       1.48412022e+03, 5.31829197e+03, 5.00913711e+03, 5.17428005e+00,\n",
      "       2.51898351e+01, 8.96521238e+02, 4.29622459e+03]), 'k1__k2__length_scale_bounds': [(0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0), (0.001, 10000000000.0)], 'k2__noise_level': np.float64(9.999999999999997e-06), 'k2__noise_level_bounds': (1e-05, 100000.0)}\n",
      "Feature ranking (most to least relevant):\n",
      "1. Feature 19 (Lengthscale: 2.6830)\n",
      "2. Feature 6 (Lengthscale: 2.9429)\n",
      "3. Feature 10 (Lengthscale: 3.0075)\n",
      "4. Feature 16 (Lengthscale: 3.1429)\n",
      "5. Feature 18 (Lengthscale: 3.1713)\n",
      "6. Feature 11 (Lengthscale: 3.8690)\n",
      "7. Feature 9 (Lengthscale: 3.9680)\n",
      "8. Feature 13 (Lengthscale: 4.8196)\n",
      "9. Feature 15 (Lengthscale: 5.0113)\n",
      "10. Feature 23 (Lengthscale: 5.1743)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "mod, lengthscales_gp = gaussian_process_classification(X_train_scaled, y_train)\n",
    "if not os.path.isdir('../outputs'):\n",
    "    os.makedirs('../outputs')\n",
    "predictions = mod.predict(X_test_scaled)\n",
    "output_df = pd.DataFrame({'ID': test_data.index, 'target': predictions})\n",
    "output_df.to_csv('../outputs/gp_predictions_without_na_scaled.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Optimization_Analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
